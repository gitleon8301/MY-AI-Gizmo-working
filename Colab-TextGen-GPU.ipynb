{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitleon8301/MY-AI-Gizmo-working/blob/main/Colab-TextGen-GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# oobabooga/text-generation-webui\n",
        "\n",
        "After running both cells, a public gradio URL will appear at the bottom in around 10 minutes. You can optionally generate an API link.\n",
        "\n",
        "* Project page: https://github.com/oobabooga/text-generation-webui\n",
        "* Gradio server status: https://status.gradio.app/"
      ],
      "metadata": {
        "id": "MFQl6-FjSYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "f7TVVj_z4flw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Launch the web UI with Google Drive Storage (CPU/GPU Compatible)\n",
        "\n",
        "#@markdown If unsure about the branch, write \"main\" or leave it blank.\n",
        "\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"\\033[1;32;1m\\n --> Mounting Google Drive...\\033[0;37;0m\\n\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up directories in Google Drive\n",
        "DRIVE_PATH = '/content/drive/MyDrive/text-generation-webui'\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "\n",
        "os.environ.pop('PYTHONPATH', None)\n",
        "os.environ.pop('MPLBACKEND', None)\n",
        "\n",
        "# Check if installation exists in Drive, if not install there\n",
        "if not Path(f'{DRIVE_PATH}/.git').exists():\n",
        "  print(\"\\033[1;32;1m\\n --> Installing the web UI in Google Drive. This will take a while, but only needs to be done once.\\033[0;37;0m\\n\")\n",
        "\n",
        "  %cd /content/drive/MyDrive\n",
        "  !git clone https://github.com/gitleon8301/MY-AI-Gizmo-working/tree/main\n",
        "  %cd text-generation-webui\n",
        "\n",
        "  # Install the project in an isolated environment\n",
        "  !GPU_CHOICE=A \\\n",
        "  LAUNCH_AFTER_INSTALL=FALSE \\\n",
        "  INSTALL_EXTENSIONS=FALSE \\\n",
        "  ./start_linux.sh\n",
        "else:\n",
        "  print(\"\\033[1;32;1m\\n --> Found existing installation in Google Drive. Skipping installation.\\033[0;37;0m\\n\")\n",
        "  %cd {DRIVE_PATH}\n",
        "\n",
        "# Detect GPU availability\n",
        "try:\n",
        "    import torch\n",
        "    has_gpu = torch.cuda.is_available()\n",
        "    if has_gpu:\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"\\033[1;32;1m ‚úì GPU detected: {gpu_name}\\033[0;37;0m\")\n",
        "    else:\n",
        "        print(\"\\033[1;33;1m ‚ö† No GPU detected - using CPU mode\\033[0;37;0m\")\n",
        "except:\n",
        "    has_gpu = False\n",
        "    print(\"\\033[1;33;1m ‚ö† No GPU detected - using CPU mode\\033[0;37;0m\")\n",
        "\n",
        "# Parameters - adjust based on your needs\n",
        "#@markdown ### Model Selection (choose CPU or GPU models)\n",
        "#@markdown **For GPU:** EXL2, GPTQ, AWQ formats\n",
        "#@markdown **For CPU:** GGUF formats\n",
        "\n",
        "model_url = \"https://huggingface.co/bartowski/gemma-2-9b-it-GGUF\" #@param {type:\"string\"}\n",
        "branch = \"main\" #@param {type:\"string\"}\n",
        "\n",
        "# Auto-configure flags based on GPU availability\n",
        "if has_gpu:\n",
        "    command_line_flags = \"--n-gpu-layers 128 --api\" #@param {type:\"string\"}\n",
        "else:\n",
        "    command_line_flags = \"--cpu --api\" #@param {type:\"string\"}\n",
        "\n",
        "# Always enable API and sharing\n",
        "if '--api' not in command_line_flags:\n",
        "    command_line_flags += ' --api'\n",
        "if '--share' not in command_line_flags:\n",
        "    command_line_flags += ' --share'\n",
        "\n",
        "model_url = model_url.strip()\n",
        "if model_url != \"\":\n",
        "    if not model_url.startswith('http'):\n",
        "        model_url = 'https://huggingface.co/' + model_url\n",
        "\n",
        "    # Parse model info\n",
        "    url_parts = model_url.strip('/').strip().split('/')\n",
        "    output_folder = f\"{url_parts[-2]}_{url_parts[-1]}\"\n",
        "    branch = branch.strip('\"\\' ')\n",
        "\n",
        "    if branch.strip() not in ['', 'main']:\n",
        "        output_folder += f\"_{branch}\"\n",
        "\n",
        "    model_path = Path(f\"{DRIVE_PATH}/models/{output_folder}\")\n",
        "\n",
        "    # Check if model exists and is complete\n",
        "    if model_path.exists():\n",
        "        # Check if there are any actual model files\n",
        "        model_files = list(model_path.glob('*.safetensors')) + \\\n",
        "                     list(model_path.glob('*.bin')) + \\\n",
        "                     list(model_path.glob('*.gguf'))\n",
        "\n",
        "        if model_files:\n",
        "            print(f\"\\033[1;32;1m ‚úì Model already exists in Drive: {output_folder}\\033[0;37;0m\\n\")\n",
        "        else:\n",
        "            print(f\"\\033[1;33;1m ‚ö† Model folder exists but appears incomplete. Cleaning and re-downloading...\\033[0;37;0m\\n\")\n",
        "            shutil.rmtree(model_path)\n",
        "            print(f\"\\033[1;32;1m --> Downloading model to Drive: {output_folder}\\033[0;37;0m\\n\")\n",
        "            if branch.strip() not in ['', 'main']:\n",
        "                !python download-model.py {model_url} --branch {branch} --clean\n",
        "            else:\n",
        "                !python download-model.py {model_url} --clean\n",
        "    else:\n",
        "        print(f\"\\033[1;32;1m --> Downloading model to Drive: {output_folder}\\033[0;37;0m\\n\")\n",
        "        if branch.strip() not in ['', 'main']:\n",
        "            !python download-model.py {model_url} --branch {branch}\n",
        "        else:\n",
        "            !python download-model.py {model_url}\n",
        "else:\n",
        "    output_folder = \"\"\n",
        "\n",
        "# Start the web UI and capture URLs\n",
        "cmd = f\"./start_linux.sh {command_line_flags}\"\n",
        "if output_folder != \"\":\n",
        "    cmd += f\" --model {output_folder}\"\n",
        "\n",
        "print(\"\\n\" + \"\\033[1;35;1m\" + \"=\"*80)\n",
        "print(\"STARTING WEB UI - WATCH FOR URLS BELOW\")\n",
        "print(\"=\"*80 + \"\\033[0;37;0m\\n\")\n",
        "\n",
        "# Run the command\n",
        "process = subprocess.Popen(\n",
        "    cmd,\n",
        "    shell=True,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    universal_newlines=True,\n",
        "    bufsize=1\n",
        ")\n",
        "\n",
        "# Monitor output for URLs\n",
        "local_url = None\n",
        "public_url = None\n",
        "urls_displayed = False\n",
        "\n",
        "for line in iter(process.stdout.readline, ''):\n",
        "    print(line, end='')\n",
        "\n",
        "    # Capture local URL patterns\n",
        "    if not local_url:\n",
        "        local_match = re.search(r'(http://(?:127\\.0\\.0\\.1|0\\.0\\.0\\.0|localhost):\\d+)', line)\n",
        "        if local_match:\n",
        "            local_url = local_match.group(1)\n",
        "\n",
        "    # Capture public URL patterns\n",
        "    if not public_url:\n",
        "        public_match = re.search(r'(https://[a-z0-9\\-]+\\.gradio\\.live)', line)\n",
        "        if public_match:\n",
        "            public_url = public_match.group(1)\n",
        "\n",
        "    # Display URLs prominently when both are found\n",
        "    if local_url and public_url and not urls_displayed:\n",
        "        print(\"\\n\" + \"\\033[1;32;1m\" + \"=\"*80)\n",
        "        print(\"üéâ WEB UI IS READY!\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"\\nüìç LOCAL URL (Colab):  {local_url}\")\n",
        "        print(f\"üåê PUBLIC URL (Share): {public_url}\")\n",
        "        print(f\"\\nüí° Click the PUBLIC URL to access from anywhere!\")\n",
        "        print(\"=\"*80 + \"\\033[0;37;0m\\n\")\n",
        "        urls_displayed = True\n",
        "\n",
        "process.wait()"
      ],
      "metadata": {
        "id": "LGQ8BiMuXMDG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}